\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{Aubry14}
\citation{Lim14}
\citation{Malisiewicz11}
\citation{Hejrati14}
\citation{pascal12}
\citation{Felzenszwalb10}
\citation{Girshick14}
\citation{Xiang12}
\citation{Pepik12}
\citation{Fidler12}
\citation{Hejrati14}
\citation{Aubry14}
\citation{Lim14}
\citation{Kholgade14}
\citation{Chen13}
\citation{Kostas14}
\citation{Lowe87}
\citation{Aubry14}
\citation{Lim14}
\citation{Dalal05}
\citation{Hariharan12}
\citation{Aubry14}
\citation{Dalal05}
\citation{Felzenszwalb10}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{\hskip -1em.~Introduction\relax }{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Using a bank of CAD models, we generate NZ-WHO templates which can be used to either detect objects directly or initialize pose of an object in the bounding box from other detectors. Once initialization is given, we use NZ-WHO to propose and validate plausible pose on-the-fly and further tune the translation, 3D viewpoint and focal length continuously.\relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:front}{{1}{1}{Using a bank of CAD models, we generate NZ-WHO templates which can be used to either detect objects directly or initialize pose of an object in the bounding box from other detectors. Once initialization is given, we use NZ-WHO to propose and validate plausible pose on-the-fly and further tune the translation, 3D viewpoint and focal length continuously.\relax \relax }{figure.caption.1}{}}
\citation{Felzenszwalb10}
\citation{Girshick14}
\citation{Xiang14}
\citation{Pepik12}
\citation{Aubry13}
\citation{Aubry14}
\citation{Lim14}
\citation{Aubry14}
\citation{Lim14}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Approach Overview}{2}{subsection.1.1}}
\citation{Hariharan12}
\citation{Martinsson05}
\citation{Belouchrani00}
\citation{Felzenszwalb10}
\citation{Girshick14}
\citation{Pepik12}
\citation{Xiang12}
\citation{Fidler12}
\citation{Xiang14}
\citation{Hejrati14}
\citation{Aubry14}
\citation{Lim14}
\citation{Xiang12}
\citation{Hejrati14}
\citation{Fidler12}
\citation{Pepik12}
\citation{Zia13}
\citation{Aubry14}
\citation{Lim14}
\citation{Aubry14}
\citation{Lim14}
\citation{Hariharan12}
\citation{vondrick2013}
\citation{vondrick2013}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Related Works}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}Whitened Histograms of Orientations (WHO)}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Pose Detection}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}2D-3D Matching using Non-Zero Whitened Histograms of Orientations(NZ-WHO)}{3}{section.3}}
\newlabel{sec:nz-who}{{3}{3}{\hskip -1em.~2D-3D Matching using Non-Zero Whitened Histograms of Orientations(NZ-WHO)\relax }{section.3}{}}
\citation{Hariharan12}
\citation{Hariharan12}
\citation{Gharbi12}
\citation{Aubry14}
\citation{Aubry14}
\citation{Dalal05}
\citation{Hariharan12}
\citation{Xiang14}
\citation{Savarese07}
\citation{Hariharan12}
\citation{Xiang14}
\citation{Savarese07}
\citation{Hariharan12}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of HOG, WHO and NZ-WHO. Visualization of positive weights (first row), visualization of negative weights (second row), HOGgles \cite  {vondrick2013} (third row). Note that for WHO, whitening all cell result in strong negative edges on the empty region\relax }}{4}{figure.caption.2}}
\newlabel{fig:whocomparison}{{2}{4}{Comparison of HOG, WHO and NZ-WHO. Visualization of positive weights (first row), visualization of negative weights (second row), HOGgles \cite {vondrick2013} (third row). Note that for WHO, whitening all cell result in strong negative edges on the empty region\relax \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Feature Statistics and Covariance Synthesis}{4}{subsection.3.1}}
\newlabel{sec:feature_statistics}{{3.1}{4}{\hskip -1em.~Feature Statistics and Covariance Synthesis\relax }{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Fast Whitening and Non-Zero Selection}{4}{subsection.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Time to generate $\Sigma $ for various number of cells (left) and same plot on log scale(right). The time complexity increases as $O(n^2)$ for $n$ number of cells.\relax }}{4}{figure.caption.3}}
\newlabel{fig:covariancetime_crop}{{3}{4}{Time to generate $\Sigma $ for various number of cells (left) and same plot on log scale(right). The time complexity increases as $O(n^2)$ for $n$ number of cells.\relax \relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Realistic rendering and depth\relax }}{4}{figure.caption.4}}
\newlabel{fig:rendering}{{4}{4}{Realistic rendering and depth\relax \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Variations of WHO}{4}{subsection.3.3}}
\citation{Savarese07}
\citation{Podlozhnyuk}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average Precision(AP) and Average Viewpoint Precision(AVP) \cite  {Xiang14} of variations of WHO on 3DObject Car dataset\cite  {Savarese07}. WHO\cite  {Hariharan12} whitens all cell, WHO-ZZ whitens all cell then zero out textureless region. NZC-WHO-ZZ first substract mean $\mu $ on non-zero cells and whiten all cells then zero out textureless region. NZ-WHO whitens only non-zero cell. Note that WHO-ZZ got dramatic performance boost after calibration due to strong impact of substracting $\mu $ from all textureless region\relax }}{5}{table.caption.7}}
\newlabel{tab:who_initializations}{{1}{5}{Average Precision(AP) and Average Viewpoint Precision(AVP) \cite {Xiang14} of variations of WHO on 3DObject Car dataset\cite {Savarese07}. WHO\cite {Hariharan12} whitens all cell, WHO-ZZ whitens all cell then zero out textureless region. NZC-WHO-ZZ first substract mean $\mu $ on non-zero cells and whiten all cells then zero out textureless region. NZ-WHO whitens only non-zero cell. Note that WHO-ZZ got dramatic performance boost after calibration due to strong impact of substracting $\mu $ from all textureless region\relax \relax }{table.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Comparison of HOG variants generation time and final \relax }}{5}{figure.caption.5}}
\newlabel{fig:whotime}{{5}{5}{Comparison of HOG variants generation time and final \relax \relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Residual of differentd method\relax }}{5}{figure.caption.6}}
\newlabel{fig:whotime}{{6}{5}{Residual of differentd method\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}\hskip -1em.\nobreakspace  {}High Resolution Templates and FFT based Convolution}{5}{subsection.3.4}}
\newlabel{sec:fft}{{3.4}{5}{\hskip -1em.~High Resolution Templates and FFT based Convolution\relax }{subsection.3.4}{}}
\citation{Aubry14}
\citation{Lim14}
\citation{Xiang12}
\citation{Pepik12}
\citation{Savarese07}
\citation{Savarese07}
\citation{Xiang14}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Effect of fine tuning. (left) original image, (middle) initial detection, (right) continuous fine tuning\relax }}{6}{figure.caption.8}}
\newlabel{fig:tuning}{{7}{6}{Effect of fine tuning. (left) original image, (middle) initial detection, (right) continuous fine tuning\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Continuous Viewpoint and Focal Length Estimation for Fine Tuning}{6}{section.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Experiments}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Object Detection}{6}{subsection.5.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Average Precision(AP) and Average Viewpoint Accuracy(AVA) on 3DObject dataset. Though we do not need any training images and made templates in few minues, it performs on par with state of the art detectors yet it gives high quality 2D-3D matching.\relax }}{6}{table.caption.9}}
\newlabel{tab:3dobject}{{2}{6}{Average Precision(AP) and Average Viewpoint Accuracy(AVA) on 3DObject dataset. Though we do not need any training images and made templates in few minues, it performs on par with state of the art detectors yet it gives high quality 2D-3D matching.\relax \relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Detection results on 3D-Object dataset \cite  {Savarese07}, each of four images have (top left) original image, (top right) top detection rendering overlaid, (bottom right) false positives, (bottom left) true positives. Each with confidence score and colored bounding box\relax }}{6}{figure.caption.10}}
\newlabel{fig:3dobject}{{8}{6}{Detection results on 3D-Object dataset \cite {Savarese07}, each of four images have (top left) original image, (top right) top detection rendering overlaid, (bottom right) false positives, (bottom left) true positives. Each with confidence score and colored bounding box\relax \relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Fine-Tuning and Viewpoint Estimation}{6}{subsection.5.2}}
\citation{Xiang14}
\citation{Pepik12}
\citation{Pepik12}
\citation{Pepik12}
\citation{Xiang14}
\citation{Xiang14}
\citation{Girshick14}
\citation{Girshick14}
\citation{Girshick14}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{Aubry14}{1}
\bibcite{Aubry13}{2}
\bibcite{Belouchrani00}{3}
\bibcite{Chen13}{4}
\bibcite{Dalal05}{5}
\bibcite{pascal12}{6}
\bibcite{Felzenszwalb10}{7}
\bibcite{Fidler12}{8}
\bibcite{Gharbi12}{9}
\bibcite{Girshick14}{10}
\bibcite{Hariharan12}{11}
\bibcite{Hejrati14}{12}
\bibcite{Lim14}{13}
\bibcite{Lowe87}{14}
\bibcite{Malisiewicz11}{15}
\bibcite{Martinsson05}{16}
\bibcite{Kholgade14}{17}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Stability of Our Method for Irregular Bounding Boxes}{7}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Stability of our method for overlapping R-CNN detection \cite  {Girshick14}. Blue box is the R-CNN detection that is feed into the system as initial detection. Purple box and overlaid rendering is the final output of the system. Note that for various overlapping bounding boxes, our system accurately estimated the reasonable result\relax }}{7}{figure.caption.12}}
\newlabel{fig:stability}{{9}{7}{Stability of our method for overlapping R-CNN detection \cite {Girshick14}. Blue box is the R-CNN detection that is feed into the system as initial detection. Purple box and overlaid rendering is the final output of the system. Note that for various overlapping bounding boxes, our system accurately estimated the reasonable result\relax \relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Conclusion}{7}{section.6}}
\bibcite{Pepik12}{18}
\bibcite{Podlozhnyuk}{19}
\bibcite{Kostas14}{20}
\bibcite{Savarese07}{21}
\bibcite{vondrick2013}{22}
\bibcite{Xiang14}{23}
\bibcite{Xiang12}{24}
\bibcite{Zia13}{25}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Average Precision(AP) and Average Viewpoint Precision(AVP) on PASCAL 3D dataset\cite  {Xiang14}. For combined method (* + Ours), we use bounding boxes from * and augment viewpoint using our method. R-CNN and run our method to produce 2D-3D matching. If our method fails to give viewpoint, it predicts the viewpoint to be 0. Note that our method gives high quality metadata such as continuous 3D viewpoint, CAD model (rendering depth) and fine-grained category, whereas base-line methods gives 1D discrete azimuths. Our R-CNN was not an optimized version so the detection AP is lower than the state-of-the-art R-CNN performance\relax }}{8}{table.caption.11}}
\newlabel{tab:pascal12}{{3}{8}{Average Precision(AP) and Average Viewpoint Precision(AVP) on PASCAL 3D dataset\cite {Xiang14}. For combined method (* + Ours), we use bounding boxes from * and augment viewpoint using our method. R-CNN and run our method to produce 2D-3D matching. If our method fails to give viewpoint, it predicts the viewpoint to be 0. Note that our method gives high quality metadata such as continuous 3D viewpoint, CAD model (rendering depth) and fine-grained category, whereas base-line methods gives 1D discrete azimuths. Our R-CNN was not an optimized version so the detection AP is lower than the state-of-the-art R-CNN performance\relax \relax }{table.caption.11}{}}
