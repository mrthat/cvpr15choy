In this section, we describe our approach to generating 3D
exemplar-based templates on-the-fly. It is based on 3D CAD model
rendering (Sect.~\ref{sec:rendering}) followed by feature extraction
and applying a whitening procedure. Based on the original whitening
formulation (Sect.~\ref{sec:who}), we propose three novel extensions that
enable the application of whitening to the on-the-fly setting.
%
First, we adapt the whitening to the specific case of rendered
images (Sect.~\ref{sec:nzwho}). Second, we show how to speed up the
whitening by two orders of magnitudes for high-resolution templates
(Sect.~\ref{sec:fastwhiten}). And third, we improve the runtime of our
3D exemplar template detectors also at test time, by performing
convolutions in the frequency domain (Sect.~\ref{sec:fft}).


\subsection{Rendering}
\label{sec:rendering}

We used an off-the-shelf rendering engine to generate a realistic rendering
and a depth map. The CAD models we used contain texture and material
information. These make the rendering more realistic and allows us to transfer
natural image statistics to rendered images. Along
with a rendering, we extracted a depth map which can be used for
reconstruction\ref{fig:rendering}.

To handle intraclass and viewpoint variability, we used various CAD models and
made renderings of these CAD models from different viewpoints.  Note that we
continuously vary yaw, pitch, roll and the focal length as well so that the
final fine tuning stage can produce accurate viewpoint estimations
(Sect.~\ref{sec:fine}).

\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.4\linewidth]{rendering}
    \includegraphics[width=0.4\linewidth]{depth}
  \end{center}
  \caption{An example rendering and depth image from renderer.}
  \label{fig:rendering}
\end{figure}


\subsection{Whitened Histograms of Orientations (WHO)}
\label{sec:who}
Our technique for rendering and generating exemplar template detectors
on-the-fly is drawing from recent work. Hariharan \etal. introduced Whitened
Histograms of Orientations (WHO), which uses feature statistics from natural
images to create a large number of classifiers analytically using Linear
Discriminant Analysis(LDA) rather than training SVM
classifiers\cite{Hariharan12}. The confidence score for data $x_i$ can be
defined as $ S(x_i) = w_{x_t}^T x_i$ where $w_{x_t} = \Sigma^{-1} (x_t - \mu)$
is an LDA classifier for a template $x_t$. Since collecting covariance matrices
for all possible template shape is intractable, \cite{Hariharan12} assumed
Wide-Sense Stationarity(WSS) of HOG features and generated a covariance
$\Sigma$ from autocovariance $\Gamma$ collected on a large collection of
natural images. i.e. for a 31 dim HOG feature $x_t$ at location $t$

\begin{align}
    E[x_t] & = \mu\\
    E[(x_{t} - \mu ) (x_{\tau} - \mu)] & = E[(x_0 - \mu)(x_{\tau - t} - \mu)]
\end{align}

In this paper, we followed their method to generate $\Sigma$.


% \begin{align}
%     S(x_i) = w_{x_t}^T x_i\\
%     w_{x_t} = \Sigma^{-1} (x_t - \mu)
% \end{align}

% The advantage of the approach is twofold: (a) you do not need a large number of
% training and hard negative mining \cite{Felzenszwalb10} (b) it takes a fraction
% of time generate (train) a discriminative template.

% templates, making them more discriminative. Whitening is a common signal
% processing operation for decorrelating a set of random variables
% \cite{Martinsson05, Belouchrani00}. More formally, suppose that we have a
% $k$-dimensional random variable $X \in \mathcal{R}^k$ with $Cov(X)=\Sigma$. By
% whitening the signal,
% 
% \begin{equation}
% \Phi(X)=\Sigma^{-\frac{1}{2}}(X - E[X]) \label{eq:whitening}
% \end{equation}
% 
% we remove 2nd order correlation between all features. Since collecting covariance
% matrix for every template shape is expensive, \cite{Hariharan12} proposed an easy
% way to synthesize
% covariance $\Sigma$ from autocovariance $\Gamma$ and we followed their
% method to generate $\Sigma$.


% More formally, suppose that we have a
% $k$-dimensional random variable $X \in \mathcal{R}^k$ with $Cov(X)=\Sigma$. By
% whitening the signal,
% \begin{equation}
% \tilde{X}=\Sigma^{-\frac{1}{2}}(X - E[X]) \label{eq:whitening},
% \end{equation}

% is independent of its place in the image, and the autocovariance of cells
% depends only on their relative location.

% The whitening and LDA have the same
% formulation when we make a decision boundary $w = \Sigma^{-1}(\mu_+ - \mu_0)$
% where $\mu_+$ is the features from a class (LDA) or a signal to whiten
% (whitening), $\mu_0$ is the negative class center (LDA) or the signal mean
% (whitening) and $\Sigma$ is the covariance matrix of classes (LDA) or
% the correlation within signal (whitening).

% In one dimension, let $x(u)$ be the feature at location $u$. Then WSS states
% that $\mathbb{E}\left[x(u)\right] = \mu$ for all $u$, and
% \begin{equation}
% \textrm{cov}_x(u,v) = \textrm{cov}_x(0, v-u) = \Gamma(v-u),
% \end{equation} where $\Gamma$ is the autocovariance. For simplicity, we describe the 1D case but this can be easily extended to 2D spatial autocovariance.
% 
% Therefore, assuming WSS allows the covariance matrix of templates \emph{of any
% size} to be synthesized from the autocovariance matrix using a simple lookup.

% However, the 
% We propose Non-Zero Whitened Histograms of Orientations (NZ-WHO), that are both
% more discriminative than WHO, and can be generated several orders of magnitude
% faster (in 70ms compared to several seconds for WHO). This speed up means we
% can generate templates on the fly, allowing our approach to evaluate arbitrary
% viewpoint hypotheses.

% Our method requires generating a covariance matrix of non-zero cells 

\subsection{Whitening Synthesized Templates and Non-Zero WHO}
\label{sec:nzwho}
Our first improvement is `Non-Zero' whitening. When synthesizing detection
templates from rendered images, a common problem is how to handle the
background. If the model is rendered over a natural image background, gradients
in the background will be incorporated into the discriminative template.

Alternatively, if the background is left textureless (see
Fig.~\ref{fig:rendering}), whitening the resulting HOG template
, strong negative weights are introduced in the textureless region (by
subtracting the mean $\mu$) as seen in Fig.~\ref{fig:whocomparison}.
This could result in positive matches being suppressed due to spurious
background gradients.

NZ-WHO removes these artifacts so that the background has no effect on the
template response. Let a vectorized HOG features of a rendering image $x = [
\begin{array}{ccccc}x_1^T & x_2^T & \cdots & x_n^T\end{array} ]^T \in
\mathcal{R}^{nd}$ where $x_i$ is the $i$th HOG cell feature and $n$ is the
number HOG cells and $d$ is the dimension of HOG feature. We create a new
vector $\bar{x}$ which contains only the non-zero HOG cell features of $x$. To be
specific, let $I_d\in \mathcal{R}^{d\times d}$ be the identity matrix, $\bar{n}$ be
the number of non-zero HOG cells, and a matrix $S\in \mathcal{R}^{\bar{n}d \times
    nd}$ be the masking matrix that selects non-zero HOG cells. For instance, a
template has  $n=3, \bar{n}=2$, and only the second HOG cell has $0$ norm, then

\begin{align}
    S = \left[ \begin{array}{ccc}
        I_d & \mathbf{0} & \mathbf{0}\\
        \mathbf{0} & \mathbf{0} & I_d
        \end{array} \right]
\end{align}

The matrix selects HOG features that corresponds to the first cell and the third cell. 

Using the selector $S$, we can define new vectorized HOG features $\bar{x} = S x,
\bar{\mu} = S\mu, \bar{\Sigma} = S \Sigma S^T$. After solving the resulting system (which
is now smaller than in the WHO approach) we find

\begin{equation}
    \bar{w}=\bar{\Sigma}^{-1}(\bar{x} - \bar{\mu}) \label{eq:nz-who},
\end{equation}

To speed up the convolution, we restore zero cells and reshape the vector $\bar{w}$
and compute convolution.

% Notice that $\Sigma$ is not square-rooted in Eq.~\ref{eq:nz-who}, whereas it is
% in the definition of whitening (Eq.~\ref{eq:whitening}). This is because the
% whitened template will only be used in the context of detection, which involves
% the inner product with the whitened HOG features of the query image $y$:
% \begin{equation}
% (y-\mu)^{T}\Sigma^{-\frac{1}{2}}\Sigma^{-\frac{1}{2}}(x-\mu)\\
% = (y-\mu)^{T} w.
% \end{equation}
% We can therefore capture the whitening of the query image features in $w$.

% We use the GPU to parallelize the lookup of the correct autocovariance cells during covariance matrix syntheses, which is \scream{x} times faster than using the CPU (Figure \ref{fig:covariancetime}).

%\scream{chris:We propose Non-Zero Whitened Histograms of Orientations (NZ-WHO), an improvement over WHO which is both more discriminative than WHO and can be computed many orders of magnitude faster than WHO (70ms as opposed to to several seconds for WHO). This speedup allows us to generate NZ-WHO templates on the fly, allowing us to quickly evaluate arbitrary viewpoint hypotheses.}
%\scream{add comments about the fig:whocomparison}

\begin{figure}[t]
  \begin{center}
%   \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    % include whitening all centered cells
    % \includegraphics[width=0.32\linewidth]{whiten_all_crop}
    \setlength\tabcolsep{3pt}
    \begin{tabular}{ccc}
      HOG & WHO & NZ-WHO \\
%     \begin{turn}{90}$w_+$\end{turn} &
    \includegraphics[width=0.28\linewidth]{hog_crop} &
    \includegraphics[width=0.28\linewidth]{whiten_all_crop} &
    \includegraphics[width=0.28\linewidth]{whiten_non_zero_crop} \\
    % include whitening all centered cells
     % \includegraphics[width=0.282\linewidth]{whiten_all_neg_crop} 
%     \begin{turn}{90}$-w_-$\end{turn} &
     \includegraphics[width=0.28\linewidth]{hog_neg_crop} &
     \includegraphics[width=0.28\linewidth]{whiten_all_neg_crop}  &
     \includegraphics[width=0.28\linewidth]{whiten_non_zero_neg} \\
    % include whitening all centered cells
 %    \begin{turn}{90}ihog\cite{vondrick2013}\end{turn} &
    % \cite{vondrick2013}& 
     \includegraphics[width=0.28\linewidth]{ihog_hog200_crop.png} &
     \includegraphics[width=0.28\linewidth]{ihog_whiten_all200_crop.png} &
     \includegraphics[width=0.28\linewidth]{ihog_whiten_non_zero200_crop.png} \\
 \end{tabular}
  \end{center}
  \caption{Comparison of HOG, WHO and NZ-WHO. Visualization of positive weights (first row),  visualization of negative weights (second row), HOGgles \cite{vondrick2013} (third row). Note that for WHO, whitening all cell result in strong negative edges on the empty region}
  \label{fig:whocomparison}
\end{figure}


\subsection{Fast Whitening using Conjugate Gradient}
\label{sec:fastwhiten}
% To speed up LDA synthesize, we introduced Conjugate Gradient method.
% for solving the matrix inversion Eq.~\ref{eq:nz-who}.
% This process speeds up , making it applicable to an on-the-fly rendering setting.
% It originates from the insight that an iterative Conjugate Gradient method can be used to whiten a HOG template, which is much faster than the original procedure proposed in~\cite{Hariharan12} based on decomposition.

Synthesizing an LDA template Eq.~\ref{eq:nz-who} requires solving the system of
linear equations, $\bar{\Sigma} \bar{w} = (\bar{x} - \bar{\mu})$. In
\cite{Hariharan12}, the authors make use of the fact that covariance matrices
are symmetric and positive semidefinite to solve the system via the Cholesky
decomposition with Gaussian Elimination, which requires $O(n^3)$ time.

The Conjugate Gradient method is an iterative algorithm for solving symmetric
positive definite systems which runs in $O(n^2\kappa)$ time, where $\kappa$ is
the condition number of the matrix. \cite{Shewchuk94}.
%
This makes Conjugate Gradient faster than decomposition for matrices with small
condition numbers relative to their size.

The covariance matrix for HOG templates is typically
ill-conditioned\cite{Hariharan12}, but adding a small regularization constant to
the diagonal reduces its condition number.
We use a constant of $0.15$, which reduces the condition number from $10^{20}$
to $50$, much smaller than the dimension of the matrix (7000).

As a result, a GPU implementation of conjugate gradient converges in 60
ms when using 250 HOG cells on Nvidia GTX660, two orders of magnitude faster
than the using Cholesky factorization with Gaussian Elimination.

We report the real time analysis of whitening using decomposition and
conjugate gradient methods in Fig.~\ref{fig:whotime}. (a) compares the
absolute runtime of the different methods while (b) gives the obtained
speedup. We see that % We compare the speed of each of template generation methods in
% Fig.~\cite{fig:covariancetime_crop} Using naive Cholesky decomposition,
WHO template takes several seconds for realistic template sizes of
several hundred cells, while using the iterative Conjugate Gradient
method, it only takes 60ms. If we use NZ-WHO, we can gain extra speed
up since we only whitens non-zero cells.

In addition, since the iterative Conjugate Gradient method directly
tries to reduce the residual (the norm of $y-Ax$ for $Ax = y$), it is
more numerically stable than Cholesky decomposition with Gaussian
Elimination. We vary the number of cells in a template and show that
the residual of NZ-WHO is smaller than WHO Fig.~\ref{fig:whoresidual}.
% Also, the residual from the Conjugate Gradient method (the norm of $y-Ax$ for $Ax = y$) is smaller than 
% that of Cholesky decomposition. 

\begin{figure}[t]
  \begin{center}
  \begin{tabular}{cc}
     \includegraphics[width=0.5\linewidth]{whotime} & 
     \includegraphics[width=0.5\linewidth]{speedup}\\
     (a) & (b) \\
 \end{tabular}
  \end{center}
  \caption{(a) Runtime analysis of whitening. HOG means feature
    extraction time, WHO-Chol uses ~\cite{Hariharan12} and
    WHO-CG uses iterative Conjugate Gradient. NZ-WHO-CG (Ours) uses only
    non-zero cells and Conjugate Gradient. (b) final speedup
    of NZ-WHO vs. WHO.}
  \label{fig:whotime}
\end{figure}
%
\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\linewidth]{residual}
  \caption{Residuals from different method}
  \label{fig:whoresidual}
\end{figure}


\subsection{High Resolution Templates and FFT based Convolution}
\label{sec:fft} 

We generate high resolution templates with more than 250 HOG cells to capture
details of an object to give accurate 2D-3D matching. These large templates
cause computational burden when computing convolution. Though good for
detecting accurate model and pose, convolution of high-resolution templates are
much slower since computation time scales linearly with the number of HOG
cells in the template. To overcome and speed up the convolution, we used FFT
based GPU convolution \cite{Podlozhnyuk} which scales. Briefly, for length $n$
signal and length $m$ filter, naive convolution takes $O(nm)$ time whereas
FFT-based convolution takes $O\left( (n + m)\log (n+m) \right)$ time. For large
$m$ (high resolution templates), we can gain computational advantage.
