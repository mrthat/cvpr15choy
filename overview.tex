% \begin{comment}
% Our method attempts to match CAD models to 2D images, determining the best
% model within a class, its pose and scale, and the focal length of the camera
% used to produce the image. These parameters are first coarsely estimated using
% an ensemble of templates generated offline, before they are refined using
% MCMC by generating new detectors on the fly.
% 
% % The basic detection method underlying our approach is WHO template matching.
% % However, we propose a new WHO variant called Non-Zero Whitened Histograms of
% % Orientations (NZ-WHO), where the variant of WHO templates are made from 
% % synthetic rendering to with 
% 
% Our method In addition to the library of CAD models that will be matched to the query
% images, our method requires a feature statistics which can be collected once and for all.
% 
% % images, our method requires a collection of random natural images. Offline, we
% % compute HOG features of these images and record their mean and spatial
% % autocovariance. The images are not used during testing, only the statistics
% % generated from them.
% 
% Notably, we do not require any labelled training images of the objects to be
% detected. Our templates are generated exclusively by rendering CAD models from
% our library. From these renderings we produce novel HOG-like features we call
% Non-Zero Whitened Histograms of Orientations (NZ-WHO), which use the natural
% image statistics found offline to whiten a standard HOG template, making it
% more discriminative.
% 
% The matching proceeds in two steps: First, we apply a bank of pre-trained
% detectors to the image, corresponding to a set of discrete viewpoints, scales,
% and object models. This provides a rough estimate of these parameters. Second,
% we refine these parameters using MCMC, where each candidate is evaluated by
% rendering a new whitened template on the fly. 
% 
% Our ensemble of NZ-WHO templates can work as a detector but our algorithm 
% can be initialized using proposal bounding boxes from
% state-of-the-art object detectors \cite{Felzenszwalb10,Girshick14} before
% executing the two steps above. In this scenario, our approach provides a means
% to augment standard bounding box detectors with more interesting 3D
% information.
% \end{comment}

% \begin{comment}

Our method has two modes of operation.

{\em (i)} it can be run in isolation, as a sliding window object
detector, similar in spirit to exemplar SVM~\cite{Malisiewicz11}. In
that case, it can not only provide a detection bounding box but also
meta-data such as viewpoint or 3D CAD model exemplar.
As we show in our experiments, our method in isolation delivers
performance that is on par with state-of-the-art for the task of
object class detection and viewpoint estimation while at the same time
being much faster to train and requiring no training images(Sect.~\ref{sec:exp_iso}).

{\em (ii)} it can be used to enrich the detections of another object
class detector that proposes candidate regions that can then be
refined by our method. This second mode of operation constitutes the
strength of our method, as we will show in our experiments
(Sect.~\ref{sec:experiments}).

Both modes of operation rely on the succession of two steps:
on-the-fly generation of exemplar templates, based on a novel whitened
feature representation termed NZ-WHO (Sect.~\ref{sec:approach}), and
pose fine-tuning using MCMC (Sect.~\ref{sec:fine}).




% with rich annotations. 
% mode uses the common path that goes from initializtion to fine
% tuning~\ref{fig:front}.  

% For both modes, they require pose initialization by an ensemble of
% NZ-WHO templates. We will explain the NZ-WHO generation pipeline in
% Sect.~\ref{sec:approach}. First stage of pipeline starts from
% rendering an viewpoint specific template in
% Sect.~\ref{sec:rendering}. Then we will go over our novel combination
% of rendering with Conjugate Gradient method to produce a
% discriminative NZ-WHO template quickly in subsequent sections from
% Sect.~\ref{sec:who} to Sect.~\ref{sec:fastwhiten}.

% Once we make an ensemble of NZ-WHO templates, we use it as a
% initialization for subsequent fine tuning stage where our model
% further tunes the 2D-3D matching (Sect.~\ref{sec:fine}).

% For mode (i), we start from detection bounding boxes that has little
% to no metadata and run initialization stage and tuning stage.


% For mode (ii), we start directly from initialization by applying our
% ensemble of NZ-WHO templates as an ensemble of exemplar detectors.

% To validate our approache, in Sect.~\ref{sec:experiments}, we (a)
% compare the performance of NZ-WHO with other variants of WHO, (b) run
% the mode (i) on PASCAL 3D dataset~\cite{Xiang14} and (c) run the mode
% (ii) on 3D Object dataset~\cite{Savarese07}.









% % Might use the following in introduction
% \scream{More like an intro than an overview:
% Our method is in line with \cite{Aubry14, Lim14} in the sense that we
% use only renderings, not real images. However, rather than using fixed
% sized mid-level patches, 

% \scream{The following part is too harsh}
% we use whole objects to make root
% templates. By using root templates, there is no need to learn a
% discriminative patch dictionary \cite{Aubry13, Aubry14, Lim14}, calibrate the patches \cite{Aubry14, Lim14}
% nor add inference stage that uses spatial configuration \cite{Aubry14, Lim14}. 

% However, whitening the whole template is prohibitive for several reasons. All templates have
% different aspect ratios making it difficult to generate the covariance
% matrix $\Sigma$. Since the root templates are larger than mid-level
% patches, a very large auto-covariance $\Gamma$ is required. Lastly,
% time complexity of decorrelating a template with $n$ cells increases
% as $O(n^3)$, resulting in slow template generation and large residuals
% due to numerical errors accumulated while decomposing the covariance
% matrix $\Sigma$.

% To overcome these difficulties, we propose the Non-Zero Whitened
% Histograms of Orientations (NZ-WHO) with iterative Conjugate Gradient to
% generate templates in real time and enrich rectangular boxes with high
% quality 2D-3D matching. The 2D-3D matching provides a CAD model,
% sub-category, rendering, depth, viewpoint and focal length.

% Our method can work as a standalone 2D-3D matching algorithm, or even
% as a standalone ensemble of exemplar-based object detectors (Figure
% \ref{fig:front}) but its real power comes from combining generic
% object detectors and complement rectangular bounding boxes. Our method
% is simple in design; is several orders of magnitude faster than
% traditional method; requires only CAD models; does not need neither images nor
% calibration, yet is powerful in giving high-quality metadata. These
% properties make our method ideal for complementing object detections. 

% To complement detection bounding boxes, we first search possible 2D-3D
% matching by running cached discrete viewpoint templates to initialize MCMC
% continuous fine tuning stage. Then it refines continuous pose, focal length and
% discrete CAD model index, scale translation. Since it requires iterations of
% proposal and validation, we
% present real time analysis of NZ-WHO template generation to show that
% this can be done on-the-fly. The fine tuning stage process jointly
% optimizes translation, yaw, roll, pitch, scale, and focal length
% continuously and also searches for different CAD models.}
