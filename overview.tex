% \begin{comment}
% Our method attempts to match CAD models to 2D images, determining the best
% model within a class, its pose and scale, and the focal length of the camera
% used to produce the image. These parameters are first coarsely estimated using
% an ensemble of templates generated offline, before they are refined using
% MCMC by generating new detectors on the fly.
% 
% % The basic detection method underlying our approach is WHO template matching.
% % However, we propose a new WHO variant called Non-Zero Whitened Histograms of
% % Orientations (NZ-WHO), where the variant of WHO templates are made from 
% % synthetic rendering to with 
% 
% Our method In addition to the library of CAD models that will be matched to the query
% images, our method requires a feature statistics which can be collected once and for all.
% 
% % images, our method requires a collection of random natural images. Offline, we
% % compute HOG features of these images and record their mean and spatial
% % autocovariance. The images are not used during testing, only the statistics
% % generated from them.
% 
% Notably, we do not require any labelled training images of the objects to be
% detected. Our templates are generated exclusively by rendering CAD models from
% our library. From these renderings we produce novel HOG-like features we call
% Non-Zero Whitened Histograms of Orientations (NZ-WHO), which use the natural
% image statistics found offline to whiten a standard HOG template, making it
% more discriminative.
% 
% The matching proceeds in two steps: First, we apply a bank of pre-trained
% detectors to the image, corresponding to a set of discrete viewpoints, scales,
% and object models. This provides a rough estimate of these parameters. Second,
% we refine these parameters using MCMC, where each candidate is evaluated by
% rendering a new whitened template on the fly. 
% 
% Our ensemble of NZ-WHO templates can work as a detector but our algorithm 
% can be initialized using proposal bounding boxes from
% state-of-the-art object detectors \cite{Felzenszwalb10,Girshick14} before
% executing the two steps above. In this scenario, our approach provides a means
% to augment standard bounding box detectors with more interesting 3D
% information.
% \end{comment}

% \begin{comment}
To give better pose estimation, our method consists of a sequence of stages each with specific task (see Fig.~\ref{fig:front}). (Our objective is to complement strong object detectors that give little to no metadata such as Neural Nework based detectors~\cite{Girshick14, Overfeat} and deformable models~\cite{gu10eccv,Xiang12,Pepik12,Fidler12,Hejrati14} 

\scream{More like an intro than an overview:
Our method is in line with \cite{Aubry14, Lim14} in the sense that we
use only renderings, not real images. However, rather than using fixed
sized mid-level patches, 

\scream{The following part is too harsh}
we use whole objects to make root
templates. By using root templates, there is no need to learn a
discriminative patch dictionary \cite{Aubry13, Aubry14, Lim14}, calibrate the patches \cite{Aubry14, Lim14}
nor add inference stage that uses spatial configuration \cite{Aubry14, Lim14}. 

However, whitening the whole template is prohibitive for several reasons. All templates have
different aspect ratios making it difficult to generate the covariance
matrix $\Sigma$. Since the root templates are larger than mid-level
patches, a very large auto-covariance $\Gamma$ is required. Lastly,
time complexity of decorrelating a template with $n$ cells increases
as $O(n^3)$, resulting in slow template generation and large residuals
due to numerical errors accumulated while decomposing the covariance
matrix $\Sigma$.

To overcome these difficulties, we propose the Non-Zero Whitened
Histograms of Orientations (NZ-WHO) with iterative Conjugate Gradient to
generate templates in real time and enrich rectangular boxes with high
quality 2D-3D matching. The 2D-3D matching provides a CAD model,
sub-category, rendering, depth, viewpoint and focal length.

Our method can work as a standalone 2D-3D matching algorithm, or even
as a standalone ensemble of exemplar-based object detectors (Figure
\ref{fig:front}) but its real power comes from combining generic
object detectors and complement rectangular bounding boxes. Our method
is simple in design; is several orders of magnitude faster than
traditional method; requires only CAD models; does not need neither images nor
calibration, yet is powerful in giving high-quality metadata. These
properties make our method ideal for complementing object detections. 

To complement detection bounding boxes, we first search possible 2D-3D
matching by running cached discrete viewpoint templates to initialize MCMC
continuous fine tuning stage. Then it refines continuous pose, focal length and
discrete CAD model index, scale translation. Since it requires iterations of
proposal and validation, we
present real time analysis of NZ-WHO template generation to show that
this can be done on-the-fly. The fine tuning stage process jointly
optimizes translation, yaw, roll, pitch, scale, and focal length
continuously and also searches for different CAD models.}
