\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{verbatim}
\usepackage{subcaption}
\usepackage{algorithm2e}
\usepackage{rotating}
\usepackage[space]{grffile}
\usepackage[font=small,skip=0pt]{caption}
%\DeclareMathOperator{\Tr}{Tr}
% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}
\graphicspath{ {figures/} }
% \cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% custom commands
\newcommand{\scream}[1]{{\color{red} \bf *** #1 ***}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{1}
\begin{document}

%%%%%%%%% TITLE
\title{Enriching Object Detection with 2D-3D Registration and Continuous Viewpoint}
%\title{Enrich Object Detection : 2D-3D registration and continuous viewpoint estimation}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
A large body of recent work on object detection has focused on exploiting 3D CAD
model databases to improve detection performance. Many of these approaches work
by aligning exact 3D models to images using templates generated from renderings
of the 3D models at a finite set of discrete viewpoints. The training procedures
for these approaches, however, are very expensive and require gigabytes of
memory and storage, and the viewpoint discretization hampers pose estimation
performance.

We propose an efficient method for synthesizing templates from 3D models that
runs on the fly -- that is, it quickly produces detectors for an arbitrary
viewpoint of a 3D model without expensive dataset-dependent training or template
storage. Given a 3D model and an arbitrary continuous detection viewpoint, our
method synthesizes a discriminative template by extracting features from a
rendered view of the object and decorrelating spatial dependences among the
features. Our decorrelation procedure relies on a gradient-based algorithm that
is more numerically stable than standard decomposition-based procedures, and we
efficiently search for candidate detections by computing FFT-based template
convolutions. Due to the speed of our template synthesis procedure, we are able
to perform joint optimization on continuous scale, translation, rotation, and
focal length. We provide an efficient GPU implementation of our algorithm, and
we validate its performance on 3DObject dataset and PASCAL 2012 dataset.

%     Using 3D model to detect and register the model to RGB image has been a
%     growing field of study. Recently, Aubry \etal \cite{Aubry14} and J. Lim
%     \etal \cite{Lim14} tried to estimate pose and align exact CAD model to an
%     image using part-based templates. Malisiewicz \etal \cite{Malisiewicz11}
%     also addresses the issue by transferring metadata after detection. Hejrati
%     \etal \cite{Hejrati14} uses template synthesis to detect an object. All
%     these approaches require extensive training, a lot of memory space. Also,
%     the training based approach requires defining fixed viewpoints which limit
%     themselves.  To overcome these difficulties, we propose an efficient and
%     fast way to synthesize and validate templates using on the fly realistic
%     rendering that can jointly optimize scale, translation, rotation and focal
%     length continuously. We render an object and extract features and
%     decorrelate spatial dependencies within them on the fly to make a
%     discriminative template. To speed up the decorrelation procedure, we adopt
%     a gradient based algorithm which is numerically more stable than
%     decomposition procedure. Finally, we efficiently search for candidate
%     match by computing convolution using FFT and jointly optimize to match the
%     object accurately. To speed up further, we propose an efficient GPU
%     implementation and tested on PASCAL images.

%   In contrast to other mid-level patch based 3D matching methods which
%   requires extensive training and more than 10Gb of memory space and physical
%   storage, ours require no training nor saving the templates thus enabling it
%   to run on any personal computer.  To overcome these difficulties, we propose
%   an efficient and fast way to synthesize and validate templates using on the
%   fly realistic rendering that can jointly optimize scale, translation,
%   rotation and focal length continuously. We render an object and extract
%   features and decorrelate spatial dependencies within them on the fly to make
%   a discriminative template. To speed up the decorrelation procedure, we adopt
%   a gradient based algorithm which is numerically more stable than
%   decomposition procedure. Finally, we efficiently search for candidate match
%   by computing convolution using FFT and jointly optimize to match the object
%   accurately. To speed up further, we propose an efficient GPU implementation
%   and tested on PASCAL images.

\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
\label{sec:intro}
\input{intro}
%
\section{Related Work}
\label{sec:related}
\input{related}


\section{Approach Overview}
\label{sec:nz-who}
\input{overview}

\subsection{Rendering}

We used a public rendering engine to create realistic rendering and
depth\begin{comment}\cite{Choy14render}\end{comment}. The CAD models we used
in our experiments contain color, texture and material information such as
transparency and reflectance. We tried to make the rendering as much realistic
as possible to simulate the natural image statistics. The example rendering is
in Fig. \ref{fig:rendering}. We also extracted depth information as well while
rendering to use in the reconstruction.

We used a collection of CAD models to make exemplar renderings of CAD models and for viewpoints. The
CAD models are cached so that when we fine-tune 2D-3D matching, so it can be rendered instantaneously.
We made the renderings to change focal length and yaw, pitch, roll so that we can fine tune the matching
continuously.

\begin{figure}[t]
  \begin{center}
     \includegraphics[width=0.4\linewidth]{rendering}
     \includegraphics[width=0.4\linewidth]{depth}
  \end{center}
  \caption{Example rendering and depth made by our renderer}
  \label{fig:rendering}
\end{figure}


\subsection{Whitened Histograms of Orientations (WHO)}
\label{sec:who}
Recently, Hariharan \etal. introduced Whitened Histograms of Orientations (WHO)
\cite{Hariharan12}, which uses statistics from natural images to whiten HOG
templates, making them more discriminative. Whitening is a common signal
processing operation for decorrelating a set of random variables
\cite{Martinsson05, Belouchrani00}. More formally, suppose that we have a
$k$-dimensional random variable $X \in \mathcal{R}^k$ with $Cov(X)=\Sigma$. By
whitening the signal,
\begin{equation}
\tilde{X}=\Sigma^{-\frac{1}{2}}(X - E[X]) \label{eq:whitening}
\end{equation}
, we remove 2nd order correlation between all features. Since covarinace
collection is expensive, \cite{Hariharan12} proposed easy way to generate
covariance $\Sigma$ from autocovariance $\Gamma$

% The whitening and LDA have the same
% formulation when we make a decision boundary $w = \Sigma^{-1}(\mu_+ - \mu_0)$
% where $\mu_+$ is the features from a class (LDA) or a signal to whiten
% (whitening), $\mu_0$ is the negative class center (LDA) or the signal mean
% (whitening) and $\Sigma$ is the covariance matrix of classes (LDA) or
% the correlation within signal (whitening).

% In \cite{Hariharan12}, the authors compute the mean and covariance matrix by assuming Wide-Sense Stationarity (WSS) of HOG features
% generated from natural images. That is, they assume the mean of a HOG cell is
% independent of its place in the image, and the autocovariance of cells depends
% only on their relative location.

% In one dimension, let $x(u)$ be the feature at location $u$. Then WSS states
% that $\mathbb{E}\left[x(u)\right] = \mu$ for all $u$, and
% \begin{equation}
% \textrm{cov}_x(u,v) = \textrm{cov}_x(0, v-u) = \Gamma(v-u),
% \end{equation} where $\Gamma$ is the autocovariance. For simplicity, we describe the 1D case but this can be easily extended to 2D spatial autocovariance.
% 
% Therefore, assuming WSS allows the covariance matrix of templates \emph{of any
% size} to be synthesized from the autocovariance matrix using a simple lookup.

% However, the 
% We propose Non-Zero Whitened Histograms of Orientations (NZ-WHO), that are both
% more discriminative than WHO, and can be generated several orders of magnitude
% faster (in 70ms compared to several seconds for WHO). This speed up means we
% can generate templates on the fly, allowing our approach to evaluate arbitrary
% viewpoint hypotheses.

% Our method requires generating a covariance matrix of non-zero cells 

\subsubsection{Whitening Synthesized Templates and Non-Zero WHO}
\label{sec:nzwho}
Our first innovation is `Non-Zero' whitening. When synthesizing detection
templates from rendered images, a common problem is how to handle the
background. If the model is rendered over a natural image background, gradients
in the background will be incorporated into the discriminative template,
potentially causing false-positives if background elements exist in the query
image.

Alternatively, if the background is left textureless (see
Fig.~\ref{fig:rendering}), whitening the resulting HOG template
will produce undesirable background artifacts. These are created when centering
the template (by subtracting the mean $\mu$), where strong negative weights are
introduced in the textureless region (as seen in Fig.~\ref{fig:whocomparison}).
This could result in positive matches being suppressed due to spurious
background gradients.

NZ-WHO removes these artifacts so that the background has no effect on the
template response. Given HOG features $x$, we create a new vector $x'$ which
contains only the non-zero elements of $x$. We select the same elements of
$\mu$ to produce $\mu'$, while the autocovariance lookup is only performed for
the cells with non-zero gradient, producing $\Sigma'$ corresponding to the
features in $x'$. After solving the resulting system (which is now smaller than
in the WHO approach) we find

\begin{equation}
w'=\Sigma'^{-1}(x' - \mu') \label{eq:nz-who},
\end{equation}which we reassemble into the final NZ-WHO template $w$ by
replacing the non-zero elements of $x$ with the corresponding $w'$ element.

% Notice that $\Sigma$ is not square-rooted in Eq.~\ref{eq:nz-who}, whereas it is
% in the definition of whitening (Eq.~\ref{eq:whitening}). This is because the
% whitened template will only be used in the context of detection, which involves
% the inner product with the whitened HOG features of the query image $y$:
% \begin{equation}
% (y-\mu)^{T}\Sigma^{-\frac{1}{2}}\Sigma^{-\frac{1}{2}}(x-\mu)\\
% = (y-\mu)^{T} w.
% \end{equation}
% We can therefore capture the whitening of the query image features in $w$.

% We use the GPU to parallelize the lookup of the correct autocovariance cells during covariance matrix syntheses, which is \scream{x} times faster than using the CPU (Figure \ref{fig:covariancetime}).

%\scream{chris:We propose Non-Zero Whitened Histograms of Orientations (NZ-WHO), an improvement over WHO which is both more discriminative than WHO and can be computed many orders of magnitude faster than WHO (70ms as opposed to to several seconds for WHO). This speedup allows us to generate NZ-WHO templates on the fly, allowing us to quickly evaluate arbitrary viewpoint hypotheses.}
\scream{add comments about the fig:whocomparison}

\begin{figure}[t]
  \begin{center}
%   \fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
    % include whitening all centered cells
    % \includegraphics[width=0.32\linewidth]{whiten_all_crop}
    \setlength\tabcolsep{3pt}
    \begin{tabular}{ccc}
      HOG & WHO & NZ-WHO \\
%     \begin{turn}{90}$w_+$\end{turn} &
    \includegraphics[width=0.28\linewidth]{hog_crop} &
    \includegraphics[width=0.28\linewidth]{whiten_all_crop} &
    \includegraphics[width=0.28\linewidth]{whiten_non_zero_crop} \\
    % include whitening all centered cells
     % \includegraphics[width=0.282\linewidth]{whiten_all_neg_crop} 
%     \begin{turn}{90}$-w_-$\end{turn} &
     \includegraphics[width=0.28\linewidth]{hog_neg_crop} &
     \includegraphics[width=0.28\linewidth]{whiten_all_neg_crop}  &
     \includegraphics[width=0.28\linewidth]{whiten_non_zero_neg} \\
    % include whitening all centered cells
 %    \begin{turn}{90}ihog\cite{vondrick2013}\end{turn} &
    % \cite{vondrick2013}& 
     \includegraphics[width=0.28\linewidth]{ihog_hog200_crop.png} &
     \includegraphics[width=0.28\linewidth]{ihog_whiten_all200_crop.png} &
     \includegraphics[width=0.28\linewidth]{ihog_whiten_non_zero200_crop.png} \\
 \end{tabular}
  \end{center}
  \caption{Comparison of HOG, WHO and NZ-WHO. Visualization of positive weights (first row),  visualization of negative weights (second row), HOGgles \cite{vondrick2013} (third row). Note that for WHO, whitening all cell result in strong negative edges on the empty region}
  \label{fig:whocomparison}
\end{figure}


\subsubsection{Fast Whitening using Conjugate Gradient}

The computational efficiency of our approach comes from using the iterative
conjugate gradient method to whiten the HOG template. Whitening the non-zero
feature vector $x'$ requires a system of linear equations $\Sigma' w' = (x' -
\mu')$ to be solved. In
\cite{Hariharan12}, the authors make use of the fact that covariance matrices
are symmetric and positive semidefinite to solve the system via the Cholesky
decomposition, which requires $O(n^3)$ time.

The conjugate gradient method is an iterative algorithm for solving symmetric
positive definite systems which runs in $O(n^2\kappa)$ time, where $\kappa$ is
the condition number of the matrix.
This makes conjugate gradient faster than decomposition for matrices with small condition
numbers relative to their size.

The covariance matrix for HOG templates is typically ill-conditioned\cite{Hariharan12}, but we
can add a regularization constant to the diagonal to reduce its condition
number to the point where the conjugate gradient method will converge quickly.
We use a constant of $0.15$, which reduces the condition number from $10^{20}$
to $50$, much smaller than the dimension of the matrix (7000).

As a result, a GPU implementation of conjugate gradient converges in 50
ms when using 250 HOG cells, two orders of magnitude faster than the system can be solved using the
Cholesky factorization.

\begin{figure}[t]
  \begin{center}
  \begin{tabular}{cc}
     \includegraphics[width=0.5\linewidth]{whotime} & 
     \includegraphics[width=0.5\linewidth]{speedup}\\
     (a) & (b) \\
 \end{tabular}
  \end{center}
  \caption{(a) Comparison of WHO variants generation time and HOG extraction time (b) final speed of using NZ-WHO compare to WHO}
  \label{fig:whotime}
\end{figure}

We compare the speed of each of template generation methods in
Fig.~\cite{fig:covariancetime_crop} Using naive Cholesky decomposition,
WHO template takes several seconds. But, if we use iterative Conjugate Gradient method, it only
takes 100ms. If we use NZ-WHO, we can gain extra speed up since we only whitens non-zero cells.

\subsubsection{Fast Convolution using the FFT}

% We compare the performance of WHO and NZ-WHO on 3D Object dataset \cite{Savarese07} and report performance on Table \ref{tab:who_initializations}. 

% To deal with the problems, we propose Non-Zero Whitened Histograms of Orientations.

% To accommodate the growing usage of rendering image for 2D-3D matching using
% WHO\cite{Aubry13, Aubry14, Lim14}, we analyzed various methods to whiten
% synthetic rendering image and propose Non-Zero Whitened Histograms of
% Orientations (NZ-WHO) which is a direct extension of \cite{Hariharan12}
% designed for rendering images with textureless background. % Since a NZ-WHO
% template has zero-mean and all elements in the template follow same
% distribution, no explicit calibration is required if all the templates have
% approximately the same number of cells. 

% Since Combining NZ-WHO with Conjugate Gradient, 

% \subsection{Non-Zero Whitened Histograms of Orientations (NZ-WHO)}
% why non zero whitening and why it makes more sense than seeing 3D, IKEA
% Overview of the subsections
%   Generating covariance quickly
%   Fast inversion
%   Regularization
% Overview of the subsections
% In this section, we will give a brief overview of whole whitening stages. In the first section \ref{feature_statistics}, we will discuss about first and second order statistics of HOG feature. Then, we will discuss about using autocovariance $\Gamma$ to create covariance matrix $\Sigma$ for non-zero cells and SIMD implementation to speed up the generation. Then, we will explain fast and accurate way to solve $w = \Sigma^{-1}x$ using Conjugate Gradient method. % Finally, we will analyze the effect of regularization.

% \subsection{Whitening and Textureless Background}
\begin{comment}
\subsection{Constructing the Covariance Matrix}
\label{sec:feature_statistics}
% Whats used in our work and using Autocovariance matrix
We first collected the first and second order statistics (mean and
autocovariance) of HOG features from arbitrary natural images. Following
\cite{Hariharan12}, we assume Wide-Sense Stationarity (WSS) of HOG features
generated from natural images. That is, we assume the mean of a HOG cell is
independent of its place in the image, and the autocovariance of patches depends
only on their relative location.

In one dimension, let $x(u)$ be the feature at location $u$. Then WSS states
that $\mathbb{E}\left[x(u)\right] = \mu_x$ for all $u$, and
\begin{equation}
\textrm{cov}_x(u,v) = \textrm{cov}_x(0, v-u) = \Gamma(v-u),
\end{equation} where $\Gamma$ is the autocovariance. For simplicity, we show the 1D case but this can be easily extended to 2D spatial autocovariance.

Therefore, assuming WSS allows us to synthesize the covariance matrix for
templates \emph{of any size} from the autocovariance matrix. This hugely reduces
the memory required because to build the covariance matrix of a template of $w
\times h$ HOG cells (with 31 elements per cell), we only need a $w \times h
\times 31$ autocovariance matrix. In comparison, the covariance matrix itself is
$(w \times h \times 31) \times (w \times h \times 31)$. Furthermore, by using
the autocovariance we can avoid storing the covariance matrix for every
different aspect ratio used during detection.

To further simplify $\Gamma$, we assumed horizontal and vertical symmetry. In
our implementation, we compute a $40 \times 40 \times 31$ autocovariance matrix,
meaning we can synthesize covariance matrices for HOG grids as big as $40 \times
40$. In practice we limit the number of cells per template to 250.

We use the GPU to parallelize the lookup of the correct autocovariance cells
during covariance matrix syntheses. The real time analysis for various number of cells is on Figure \ref{fig:covariancetime}).

\end{comment}

% Since the statistics have been computed for a generic HOG feature, we can use
% the same statistics for all templates and images. In practice, since it is
% expensive to whiten all the sliding patches in the image, we followed
% \cite{Hariharan12} and defined the templates to be $w =
% \Sigma^{-1}(X-E[X])$\begin{comment}which is a good approximation of
% $\Sigma^{-\frac{T}{2}} \Sigma^{-\frac{1}{2}}(X-E[X])$\end{comment} 

% \begin{comment}Gathering statistics, especially computing spatial covariance
% of a signal is computationally burdensome. \end{comment} To speed up the
% statistics collection, \begin{comment}in addition to the wide-sense
% stationarity (WSS) of HOG, \end{comment}we assumed horizontal and vertical
% symmetry of covariance. 

 %Hariharan \etal \cite{Hariharan12} interpreted the whitening also as the
 %Linear Discriminant Analysis where each class has the same covariance $\Sigma$
 %but with different mean value. They defined this whitened HOG feature as
 %Whitened Histograms of Orientations (WHO) and we will follow their convention
 %of the name.

% \subsection{Rendering}
% 
% We used a public rendering engine to create realistic rendering and
% depth\begin{comment}\cite{Choy14render}\end{comment}. The CAD models we used
% in our experiments contain color, texture and material information such as
% transparency and reflectance. We tried to make the rendering as much realistic
% as possible to simulate the natural image statistics. The example rendering is
% in Fig. \ref{fig:rendering}. We also extracted depth information as well while
% rendering to use in the reconstruction.


% To whiten a HOG features, we first have to synthesize the covariance matrix.
% Following the method of \cite{Hariharan12}, which assumes spatial Wide-Sense
% Stationarity (WSS) of a feature, covariance matrix can be synthesized using
% spatial autocovariance $\Gamma$. This assumes the \begin{comment} and features
% such as HOG are gradients in a small patch whose statistics does not change
% (an object can be in anywhere in an image)\end{comment}. 

%However, unlike small fixed-sized mid-level patches, the root templates have
%different aspect ratios, different gradient patterns and large number of HOG
%cells which results in large covariance $\Sigma \in \mathcal{R}^{7000 \times
%7000}$ that is difficult to cache. Thus, to generate a NZ-WHO template, we have
%to synthesize a covariance matrix and solve the system of linear equations. 



% Thus, every time we whiten a root template, we have to generate a covariance
% matrix using autocovariance $\Gamma$. 

%\begin{comment} Also, since we are whitening only the non-zero HOG cells whose
%position is unknown beforehand and all templates have different aspect ratio
%for , we cannot cache the matrix. Using CPU, it takes about \end{comment}

% In practice, synthesizing covariance matrix $\Sigma$ takes long time due to
% its large size.  $\Sigma$ ranges from $\Sigma \in \mathcal{R}^{7000 \times
% 7000}$ to $\Sigma \in \mathcal{R}^{7500 \times 7500}$. We vary the template
% resolution and run $\Sigma$ generation on CPU and GPU 100 times and report the
% average time in Fig. \ref{fig:covariancetime}.

% \begin{figure}[t]
%   \begin{center}
%      \includegraphics[width=0.9\linewidth]{covariancetime} 
%   \end{center}
%   \caption{Time to generate $\Sigma$ for various number of cells (left) and same plot on log scale(right). The time complexity increases as $O(n^2)$ for $n$ number of cells.}
%   \label{fig:covariancetime_crop}
% \end{figure}
 
% 1-dimensional version of SIMD implementation that generate covariance matrix $\Sigma$ from autocovariance $\Gamma$ on GPU is on the supplementary material.
% \begin{comment}i
% \begin{algorithm}
% \KwData{ $\Gamma$ , nonzero cell indexes, thread x id, thread y id}
% \KwResult{ $\Sigma$ }
% \Begin{
% $c_u \leftarrow \mod(x, N_f)$ define cell $u$ coordinate\; 
% $f_u \leftarrow u / N_f$ define feature index
% $c_v \leftarrow \mod(y, N_f)$ define cell $v$ coordinate\;
% $f_v \leftarrow v / N_f$ define feature index
% $T \leftarrow $ nonzero cell indexes\;
% $\Sigma(w) \leftarrow \Gamma( N_f ( T(u) - T(v) +  )$\;
% }
% \caption{SIMD implementation of covariance synthesis from autocovariance}
% \end{algorithm}
% \end{comment}



The final challenge in on-the-fly template evaluation is performing the
convolution between the template and the target image. Standard convolution
would be prohibitively slow for the high resolution templates we're using, so we
implemented the convolution via Fast Fourier Transform on the GPU. This allows
template evaluation to run in \scream{x ms}, compared to \scream{x ms} for the
naive CPU implementation.

  
%  If we use a high resolution template such as \ref{fig:rendering}

% where $w$ is the weight we want to find and $x$ is the HOG feature from the
% rendering and $\lambda$ is the regularization constant (see section
% \ref{sec:regularization}). For $w\in \mathcal{R}^n$, it takes $O(n^3)$ time to
% solve the linear equation. If we use a high resolution template to capture
% small geometric properties we can get high accuracy matchings but the solving
% the linear equation becomes computationally burdensome. 

% To briefly recap, the LU Decomposition and Cholesky Decomposition are most
% popular methods to solve a linear equation. In linear algebra libraries such
% as MATLAB, these decomposition methods are default method to solve a linear
% equation (backslash \textbackslash in MATLAB). Since the covariance matrix is
% Hermitian and Positive Semi-Definite, we can use Cholesky Decomposition which
% is twice as fast as the LU Decomposition.  

% decomposition methods such as LU or Cholesky Decomposition not only take long
% time but they also accumulate numerical error. 

%In our setting, we used high resolution template which has more than 250 HOG
%cells. This result in $\Sigma \in \mathcal{R}^{7500 \times 7500}$. It takes
%about 9 seconds if we use LU decomposition and 5 seconds if we use Cholesky
%decomposition.  % The default way of solving the linear equation in many linear
%algebra library is decomposing the matrix using LU Decomposition (in MATLAB the
%default method of backslash operator) which takes $O(\frac{2}{3}n^3)$ flops for
%$n\times n$ matrix. Since the matrix, $\Sigma + \lambda I$ is Hermitian and
%Positive Semi Definite. We can speed up using Cholesky Decomposition. 



%We also used iterative Conjugate Gradient to make use of low rank property of
%the covariance \cite{Gharbi12}. After adding small regularization, the
%regularized covariance matrix has nice spectral property (Figure
%\ref{fig:spectral}). The singular values are clustered in small region and most
%of the energies are concentrated on the first (number) singular values. Thus,
%the conjugate gradients stage doesn't go upto the size of the matrix to
%converge.

[Figure spectral analysis]

\begin{figure}[t]
  \centering
  \includegraphics[width=0.5\linewidth]{residual}
  \caption{Residual of differentd method}
  \label{fig:whotime}
\end{figure}

\subsection{Variations of WHO}
\scream{sam thinks this should be moved to the experiments section}
We empirically found out that NZ-WHO performs reasonably well without time
consuming calibration stage compare to other variational method to generate
templates. We used 1 CAD model with viewpoints covering 24 azimuths and 4
elevations. Each template takes approximately 80 milliseconds to generate a
NZ-WHO template. We also calibrated templates using the method presented in
\cite{Aubry14}. The calibration learns affine transformation of the detection
confidence.% Note that in Section \ref{experiments}, we provide the same
experiment with 9 CAD models.


\begin{table*}[!htbp]
    \footnotesize
    \begin{center}
\begin{tabular}{|c|c|r|c|r|}
\hline
Methods (AP/MPPE) & before calibration  & time & after calibration \cite{Aubry14} & time \\
\hline\hline
HOG\cite{Dalal05}     & 72.3 / 65.0           &  31ms  & 60.4 / 50.2                 & 8.7 sec \\ 
WHO\cite{Hariharan12} & 82.1 / 85.4           &  3811ms& 84.4 / 83.0                 & 12.4 sec  \\
WHO-CG                & 81.7 / \textbf{84.9}  &  104ms & 83.7 / 87.3                 & 8.3 sec \\
WHO-CG-Z              & 54.4 / 65.1           &  103ms & \textbf{92.8} / 86.7        & 8.7 sec  \\
% NZC-WHO-Z    & 89.10/\textbf{78.64} &    & 91.15/74.79                  &     \\
NZ-WHO-CG             & \textbf{90.0} / 82.8  &   79ms & 90.3 / \textbf{86.8}        & 8.5 sec   \\
\hline
\end{tabular}
\end{center}
\caption{Average Precision(AP) and Mean Precision in Pose Estimation (MPPE) \cite{Lopez-Sastre11} variations of WHO on 3DObject Car dataset\cite{Savarese07}. WHO refers to standard WHO using the method presented in \cite{Hariharan12}, WHO-CG uses iterative Conjugate Gradient method to generate WHO. WHO-CG-Z uses whiten the whole template and zero out textureless region. NZ-WHO-CG is the NZ-WHO which whitens only non-zero cells using iterative Conjugate Gradient method. The time column indicates the time to generate one template. We followed calibration procedure presented in \cite{Aubry14}.}
\label{tab:who_initializations}
\end{table*}

We found out that without calibration, NZ-WHO performs the best on object
detection on 3DObject car dataset \cite{Savarese07}. See Table
\ref{tab:who_initializations} for detail. In essence, if we use calibration, we
could achieve better performance but since our goal is to do 2D-3D matching and
continuous viewpoint estimation using on-the-fly template generation, we did not
calibrated our templates.


\begin{comment}
\subsection{Whitening Non-Zero Cells}

% learning weights for whitened templates
But since it is difficult to make templates to have the number of cells, \cite{Hariharan12, Aubry14, Lim14} learned weights for convolution score from the template. However, we propose a novel way to guarantee normalized score distribution by decorrelating non-zero HOG cells and forcing each template to have approximately same number of cells.

% 
Unlike \cite{Aubry14}, we did not whiten all cells and then zero out some HOG cells that are on the background. Instead, we whiten only the cells with non-zero value. We empirically found out that by whitening the cells that has non-zero support actually performs better and takes less time solving the linear equation $w = \Sigma^{-1}x$ since the number of elements to whiten decreases. However, by selecting non-zero cells, we destroys inherent Toeplitz-Block-Toeplitz property of the covariance matrix which could speed up the inversion using Fourier Transformation \cite{Akaike73, Martinsson05}.

  We propose a whitening stage for WHO feature template generation that can create template whose convolution score follow same distribution. This guarantees that we do not require any calibration stage after generating templates rapidly. We statistically compare the score distribution of whitening non-zero HOG cell only and whitening.
  \end{comment}


% \subsection{Effect of Regularization}
% \label{sec:regularization}
%  Also, since all covariance matrix is Positive Semi Definite, our matrix
%  $\Sigma$ must be Positive Semi-Definite too. To guarantee the property, We
%  found out that the regularization has significant impact on the performance.
%  In \cite{Hariharan12}, Hariharan \etal used small fixed regularization since
%  the covariance matrix of specially correlated features is intrinsically
%  row-rank to make the matrix invertible.
%  
% However if we closely analyze the impact of the regularization, we can see that larger the $\lambda$ is, the centered HOG becomes more dominant. 
% 
% \begin{align}
% (\Sigma + \lambda I)^{-1} & = \frac{1}{\lambda}\left(I + \frac{1}{\lambda}\Sigma \right)^{-1} \\
% & = \frac{1}{\lambda}\left(I - \frac{1}{\lambda} \Sigma  + \frac{1}{\lambda^2} \Sigma^{2} 
% 		- \frac{1}{\lambda^3} \Sigma^{3} + \cdots \right)
% % & = \frac{1}{\lambda}I - \left(I + \frac{1}{\lambda} \Sigma \right)^{-1} \frac{1}{\lambda^2} \Sigma
% % & = \frac{1}{\lambda}\left(I  - \frac{1}{1 + \frac{1}{\Sigma} \Tr{\Sigma}} \right)
% \end{align} 
% 
% We empirically found out that as $\lambda$ increases, AP converges to that of centered HOG feature without any whitening.

\begin{comment}
\subsection{No Calibration}
  We created coarse viewpoint templates by whitening non-zero HOG cells and compare the average precision on 3D Object dataset \cite{Savarese07} with that of whitening all HOG cells. 
  
\begin{table}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Whitening and AP & Whiten & No Whitening \\
\hline\hline
Average Precision & 89.205 & 74.478 \\
\hline
\end{tabular}
\end{center}
\caption{Effect of whitening on 3D Object Car validation set using one CAD model. The whitening dramatically increased the AP.}
\end{table}
\begin{table}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Calibration methods \&AP & Whiten non-zero & Whiten all \\
\hline\hline
None & 89.205 & 86.676 \\
Linear & 88.430 & 85.720 \\
Gaussian & 87.913 & 84.567\\
Number of non-zero cells & 84.734 & N/A\\
\hline
\end{tabular}
\end{center}
\caption{Various calibration and AP on small experimental set. Since the whitening templates with constant number of HOG cells create normalized feature, calibration using negative patches did not improve the AP.}
\end{table}
\end{comment}

\begin{comment}
\subsection{High Resolution Templates and FFT based Convolution}
\label{sec:fft} 
We generate high resolution templates with more than 250 HOG cells to capture details of an object to give accurate 2D-3D matching. These large templates cause computational burden when computing convolution. Though good for detecting accurate model and pose, convolution of high-resolution templates are much more slower since computation time scales linearly with the number of HOG cells in the template. To overcome and speed up the convolution, we propose FFT based GPU convolution which scales. Suppose there are length $n$ signal and length $m$ filter, naive convolution takes $O(nm)$ time where as FFT-based convolution takes $O\left( (n + m)\log (n+m) \right)$ time. For large $m$, high resolution template, we can gain computational advantage.


we pad zero to the 2D image features by the largest kernel size. And we transform the kernel to match the padded image feature. To compute convolution, we compute element-wise product with the transformed kernel and sum all the features. Unlike \cite{Podlozhnyuk}, we do not need to shift the data nor kernel if we use simple mathematical trick. 
  
\begin{align}
    x_{pad} & = \mathcal{P}_{n+m}(x)\\
    y_{pad} & = \mathcal{P}_{n+m}(y)\\
    x_{pad} \ast y_{pad} & = \mathcal{F}^{-1}(\mathcal{F}(x_{pad}) \circ \mathcal{F}(y_{pad}))
\end{align}

  Where $\ast$ is the circular convolution and $\circ$ is the Hadamard Product and $\mathcal{F}$ is the Fourier Transformation and $\mathcal{P}_n$ is the padding operation that append zeros to make vector of size $n$.

For each dimension of features, we transform kernel and image feature into frequency domain using Fast Fourier Transformation. We transform the image into frequency domain once and use the transformed image for all templates.

We implemented the convolution using FFT on GPU and got 10x speed up.

[Figure for convolution time for different template resolution, CPU, GPU, naive convolution]
\end{comment}
%------------------------------------------------------------------------

\section{Pose Fine-Tuning via MCMC}
\label{sec:fine}
\input{mcmc}
%
\section{Experiments}
\label{sec:experiments}
\input{experiments}



\section{Conclusion}


{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
